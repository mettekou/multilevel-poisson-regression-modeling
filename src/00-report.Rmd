```{r setup, echo=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, results = FALSE, cache = TRUE)
```

```{r libraries}
library(here) # Load here
library(readr)
library(parallel)
library(runjags)
library(dplyr) # used for arrange(), to rank hospitals
library(mcmcplots) # for running mean plot
```

```{r globals}
data_path <- "data/BurnoutPA.txt"
burn_in_iterations <- 4000
sample_iterations <- 10000
more_sample_iterations <- 30000
method <- "rjags"
max_chains <- 5
n_chains <- max_chains#min(detectCores(), max_chains)
```

```{r load}
RN4CAST_complete <- (RN4CAST <-
    read_table( # read_table has as default skip_empty_rows = TRUE, so only rows without missing data are read in
        here(data_path),
        col_names = TRUE,
        col_types = cols(
            col_integer(),
            col_integer(),
            col_factor(),
            col_factor(),
            col_integer(),
            col_factor(),
            col_double(),
            col_double(),
            col_factor(),
            col_integer()
        )
    ))
```

```{r scale}
RN4CAST_complete$beds <- c(scale(RN4CAST_complete$beds))
RN4CAST_complete$we <- c(scale(RN4CAST_complete$we))
RN4CAST_complete$expe <- c(scale(RN4CAST_complete$expe))
```

# Questions

## Part 1

**Although the variable PA does not correspond to count data, a Poisson model will be
fitted for the purpose of this exercise.**

**Fit a three-level Poisson random intercept model, with nursing unit representing the level 2
random intercept and hospital representing the level 3 random intercept. Assume normal
distributions for the random intercepts.**

- **Take vague priors for all model parameters. Determine whether an inverse gamma or a uniform prior is most appropriate for the variability parameter of the random intercepts.**

The random intercepts model we fit here partitions the total variance in variance between hospitals $\epsilon_{h}\sim N(0,\sigma_h^2)$, variance between units within a hospital $\epsilon_{h,u}\sim N(0,\sigma_{h,u}^2)$, and residual variance $\epsilon_{h,u,n}$.

- **First, fit a model without the covariates and check convergence using classical diagnostics.**

As we are asked to model the dependent variable personal accomplishment $Y$ as a Poisson random variable, we use the exponential link function to obtain the following equation:

$$\log(Y)=\beta_0+\epsilon_{h}+\epsilon_{h,u}+\epsilon_{h,u,n}$$

Here the `template.jags` function in the `rjags` package comes in. We
can use the syntax of `lme4` to specify our mixed model, and then
`template.jags` writes all the jags code. For example, to get the jags
syntax for a mixed effects model predicting reduced personal
accomplishment, with a fixed intercept, a random intercept for unit, and
a random intercept for hospital, we run the chunk below.

### Model without covariates: uniform prior for precision

The model is written down in a file, called `JAGSmodel0.txt`, in our
current directory. The default sets a $\text{Gamma}(0.001, .001)$ prior
on the precision of the two random intercepts and a vague
$\text{Normal}(0,10^{-6})$ prior on the fixed effects (in this case, a
fixed intercept only). Another default is the number of chains (2)..

In the first part of the assignment, we're asked to run exactly this
model, but instead we have to test what prior to put on the precision of
the random intercepts: an inverse gamma or a uniform.

#### Pilot model

##### Creating model

First, let's asses performance with a a $\text{Uniform}(0.001,100)$
prior. Then, we run the following chunk to get the syntax for a model
with only the intercepts, a user-specified uniform prior for the
precision, and 5 chains. The amount of chains is based on the generally
accepted heuristic that 3-5 chains are needed for more complex models:

We can now just run the model directly from `R` without needing to
manually copy/paste anything. For this, we use the `run.jags` function
to run the model we just specified our syntax for. We choose a limited
burn-in (4000) and sample (10000) to allow for an initial pilot run.
<!--- Should method=rjags be  used in original model design (see documentation extend.jags - then no need to recompile model when extending) --->

```{r}
JAGS.mod_uniform <- run.jags(
    "JAGSmodel0_unif.txt",
    data = RN4CAST_complete,
    monitor = c("intercept", "unit_precision", "hosp_precision", "deviance",
    "hosp_randomeffect"), # monitor additionally all intercepts of random effect of hospitals
    burnin = burn_in_iterations,
    sample = sample_iterations,
    method = "rjags",
    n.chains = n_chains
)
```

##### Visualization

Before assessing the model based through formal measures, we first do a
visual inspection. Various plot types are available:
`plot.type = c("trace", "ecdf", "histogram", "autocorr", "crosscorr")`.
You can also specify for which variable you want the plot. The different
options are
`vars = c("intercept", "unit_precision", "hosp_precision", "deviance", "resid.sum.sq")`.

First we create a convenience function for plotting runjags objects.

```{r}
# Convenience function for plotting
plot_jags <- function(type, var) {
    plot(JAGS.mod_uniform, plot.type = type, vars = var)
    dev.off()
}
```

For example, here are the trace plots and autocorrelation plots for the precision of the random
intercept for unit (`unit_precision`) and for hospital (`hosp_precision`):

```{r, out.width="50%", fig.align='center'}
plot_jags("trace", "unit_precision")
plot_jags("autocorr", "unit_precision")
plot_jags("trace", "hosp_precision")
plot_jags("autocorr", "hosp_precision")
rmeanplot(JAGS.mod_uniform, parms = "unit_precision")
```

The autocorrelation seems limited: for `unit_precision`, the
autocorrelation is almost zero at lag 15. For `hosp_precision`, this is
even better. The trace plot for `unit_precision` looks fairly well, although
there is limited dependency (indicated by the "zigzagging"). Yet, the running
mean plot seems to indicate a constant mean. 
For `hosp_precision`, the trace plot is similar although there seems to 
be an upper cap depending on the range of the prior (i.c. 100).

##### Assessment model

The model ran, and we can inspect its results.

```{r, results = TRUE}
JAGS.mod_uniform
```
Since the visual inspection yields stable results, we proceed to more formal measures.
The Gelman-Rubin ANOVA diagnostic (i.e. estimated potential scale
reduction factor - PSRF) is close to 1 for both the `unit_precision` and
the `hosp_precision`, which is the aim. The MCMC error is also limited
in comparison with the SD (1.0% for `unit_precision` and 0.9%
for `hosp_precision`). 

We subsequently obtain the DIC (Deviance Information Criterion) to
assess the model performance.

```{r, results = TRUE}
dic_uniform <- extract.runjags(JAGS.mod_uniform, what = "dic")
dic_uniform
```

- **Rank the hospitals according to their random effect (in WinBUGS it is possible with the rank option). Are there hospitals with important differences in the PA baseline level?**

``` {r ranked}
hosp_randomeffects <- add.summary(JAGS.mod_uniform, vars = "hosp_randomeffect") # obtain hosp_randomeffects out 
hosp_randomeffects_means <-  data.frame(print(hosp_randomeffects))["Mean"] # transform runjags.object to dataframe to enable further handling
hosp_randomeffects_ranked <- arrange(hosp_randomeffects_means, hosp_randomeffects_means$Mean) # sort intercepts

print(hosp_randomeffects_ranked)
hist(hosp_randomeffects_ranked$Mean)
```
```{r}
library(ggmcmc)
# convert the model as mcmc for convinience of extracting plots and ranking
mcmc.uniform_sample<-as.mcmc(JAGS.mod_uniform)
mcmc.sample<-ggs(mcmc.uniform_sample)

# ranking the hospitals 
jpeg("catapillar.jpeg",quality=100)
ggs_caterpillar(mcmc.sample,family=c("hosp_randomeffect"))

```

- **In a second step, include the covariates. Are there hospitals genuinely different with respect to the PA level after adjusting for the covariates in the model?**

- **Check with DIC whether the inclusion of the covariates improves the fit with respect to the baseline model. Determine what variables to include using this selection criterion.**

- **Give all necessary posterior summary measures of the relevant parameters.**

- **Hint: Standardize all numeric covariates to improve convergence of the MCMC procedure and give initial values to the regression coefficients and parameters related to variances of random effects.**

## Part 2
**In some cases, there is overdispersion compared to what we would be expect in a Poisson model.**

- **Check whether a negative binomial distribution for PA is better than a Poisson distribution.**

- **Motivate your conclusion.**





[1]: https://bmcnurs.biomedcentral.com/articles/10.1186/1472-6955-10-6 "Sermeus et al. (2011)."

to me , these are the topics on the agenda:

Please find included , my RMD output in Word, so we could copy / paste some output in the overleaf?/word, if that is helpful.


 


 

PART 1

 

Introduction as added by Leah, what procedure to follow , ...

2 models next to each other  

Q1 : Determine whether an inverse gamma or a
uniform prior is most appropriate for the variability parameter of the random intercepts.


 

DONE = 3 level intercept model is fittined with 2 prior choices
TO DO = answer the question about most 'appropiate' precision prior. (my opionion, this is also a theoretical thing : is Inverse Gamma kind of "conjugate?

TO DO : read spiegelhalter Paper on ... why inverse gamma make sense, but not using

 

Q2 : CONVERGENCE CHECK
DONE = summary output available
TO DO : SUMMARIZING and we report howto, based on BGR diagnostics, trace plot insights,      and the lag autocorrelation

classical diagnostics : just as in frequence, HIGHLIGHT diag : MCMC error , 

 
summary printout  (in table) + comment it
 
discuss 1. MCMC error (under 5%) + PSRF => BGR diagnostic measurement / effective SS
 

Q3:Rank the hospitals according to their random
this is our rank we tried out + the plot as proposed by Leah??

matrix by Niels => +/- same, 

to look for caterpillarplot and the output object  that Niels got for his matrix

do we know the 'real' impact on PA of the Random Effect hospital ,(considering scaling) 

mention the scaling we did => all effects are around 0 +/- ...

 

Q4 : with Covariates :
Report model, report plots and convergence stats, .... => SO FAR = THE MODELS ARE BUILT WITH ALL COVARIATES
DONE = MODEL WITH ALL COVARS BUILD

TO DO = output of full model and create catterpillar plot + matrix on hospitals  (same as above)
TO DO = Report what we see on (possible) differnces and Why.


 

Q5: DIC FOLLOW UP : model building
DONE : DIC FOR ALL COVARS
TO DO : compare DIC intercept model with DIC intercept + all covars
Personally = THIS IS A QUESTION WHERE WE REPORT OUR INTERPRETATION ABOUT THE DIC parameter (Mean deviance + Penalty added)

BASELINE DIC / FULL MODEL DIC / BEST MODEL DIC 

just discuss slightly our 'logical'  modeling selection approach by levels .
 


Q6: SUMMARY STATS

done , stats available
TO DO : COMMENT OUR summary stats for the full model (MCerror, DIC, ...)


SUMMARY MEASURES + discussion , focus on variable selection with DIC

effective parameters => sum of deviance + eff paramters

 

 

 

Q7 : WHEN OVERDISPERSION:

overdispersion of poisson not suitable anymore, too mean neq var anymore,

solve this with other distribution....NEG BINOMIAL DISTRO
 

1. WHAT DO WE EXPECT : 

look at distro and check which is best.

we do expect : THE TAILS ARE BIGGER IN NEG BIN then POisso, lambda not eq as var...

decouple the mean from the variance with NB


2. Is NEG BIN better => we already have the model

LOOK AT DIC for the Hierarchical fit : half of poisson distro

 

BASELINE DIC / FULL MODEL DIC / BEST MODEL DIC

fun calc : option 3 this is similar with LME4 results => our uninformative prior will .  => this proves that the distribution of data is key., and not the prior choice. 

 

3. MOtivation,
personally I would. include a general conclusion and motivation, walking through all issues and options we met during
this assignment (modeling time, convergence, parallellism, ....).

Why is the Neg Bino better than poisson => overdispersion, decoupling var and mean, FOCUS ON STATISTICS, 

side note our unknowleddge about the surevey variabiliyt.