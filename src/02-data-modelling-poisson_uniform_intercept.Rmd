---
editor_options: 
  markdown: 
    wrap: 72
---

**Questions/tasks: Part 1: Although the variable PA does not correspond
to count data, a Poisson model will be fitted for the purpose of this
exercise.**

**Fit a three-level Poisson random intercept model, with nursing unit
representing the level 2 random intercept and hospital representing the
level 3 random intercept. Assume normal distributions for the random
intercepts.**

-   **Take vague priors for all model parameters. Determine whether an
    inverse gamma or a uniform prior is most appropriate for the
    variability parameter of the random intercepts.**

The random intercepts model we fit here partitions the total variance in
variance between hospitals $\epsilon_{h}\sim N(0,\sigma_h^2)$, variance
between units within a hospital
$\epsilon_{h,u}\sim N(0,\sigma_{h,u}^2)$, and residual variance
$\epsilon_{h,u,n}$.

-   **First, fit a model without the covariates and check convergence
    using classical diagnostics.**

    As we are asked to model the dependent variable personal
    accomplishment $Y$ as a Poisson random variable, we use the
    exponential link function to obtain the following equation:

    $$Y=e^{\beta_0+\epsilon_{h}+\epsilon_{h,u}+\epsilon_{h,u,n}}$$

    -   **Rank the hospitals according to their random effect (in
        WinBUGS it is possible with the rank option). Are there
        hospitals with important differences in the PA baseline level?**

    -   **In a second step, include the covariates. Are there hospitals
        genuinely different with respect to the PA level after adjusting
        for the covariates in the model?**

    -   **Check with DIC whether the inclusion of the covariates
        improves the fit with respect to the baseline model. Determine
        what variables to include using this selection criterion.**

    -   **Give all necessary posterior summary measures of the relevant
        parameters.**

    -   **Hint: Standardize all numeric covariates to improve
        convergence of the MCMC procedure and give initial values to the
        regression coefficients and parameters related to variances of
        random effects.**

    **Part 2: In some cases, there is overdispersion compared to what we
    would be expect in a Poisson model.**

    -   **Check whether a negative binomial distribution for PA is
        better than a Poisson distribution.**

    -   **Motivate your conclusion.**

    ## Set up

    First, we load the R package `runjags`.
    <!--- delete loading `parallel` --->

```{r, message = FALSE}
library(parallel)
library(runjags)
```

```{r}
# set.seed(12345)
```

## Multilevel Poisson model using runjags

```{=html}
<!--- 
Delete modification relating to complete cases since pa has no missing values ??

`runjags` only works with complete data, so we first delete the missing
values in personal accomplishment.
--->
```
```{r}
# RN4CAST_complete <- RN4CAST[!is.na(RN4CAST$pa), ] # Delete missing values in pa
RN4CAST_complete <- RN4CAST
```


Here the `template.jags` function in the `rjags` package comes in. We
can use the syntax of `lme4` to specify our mixed model, and then
`template.jags` writes all the jags code. For example, to get the jags
syntax for a mixed effects model predicting reduced personal
accomplishment, with a fixed intercept, a random intercept for unit, and
a random intercept for hospital, we run the chunk below.

### Model without covariates: uniform prior for precision

The model is written down in a file, called `JAGSmodel0.txt`, in our
current directory. The default sets a $\text{Gamma}(0.001, .001)$ prior
on the precision of the two random intercepts and a vague
$\text{Normal}(0,10^{-6})$ prior on the fixed effects (in this case, a
fixed intercept only). Another default is the number of chains (2)..

In the first part of the assignment, we're asked to run exactly this
model, but instead we have to test what prior to put on the precision of
the random intercepts: an inverse gamma or a uniform.

#### Pilot model

##### Creating model

First, let's asses performance with a a $\text{Uniform}(0.001,100)$
prior. Then, we run the following chunk to get the syntax for a model
with only the intercepts, a user-specified uniform prior for the
precision, and 5 chains. The amount of chains is based on the generally
accepted heuristic that 3-5 chains are needed for more complex models:

```{r, message=FALSE, warning=FALSE}
model0_unif <- template.jags(
    formula = pa ~ (1 | unit) + (1 | hosp),
    data = RN4CAST_complete,
    file = "JAGSmodel0_unif.txt",
    precision.prior = "dunif(0.001, 100)", # make an informed decision later
    family = "poisson",
    write.data = FALSE,
    n.chains = 5
)
```

We can now just run the model directly from `R` without needing to
manually copy/paste anything. For this, we use the `run.jags` function
to run the model we just specified our syntax for. We choose a limited
burn-in (4000) and sample (10000) to allow for an initial pilot run.
<!--- Should method=rjags be  used in original model design (see documentation extend.jags - then no need to recompile model when extending) --->

```{r cache=TRUE}
# ?run.jags #run this for more information on the default settings
JAGS.mod_uniform <- run.jags(
    # specify the syntax file
    model0_unif,
    # specify the data source (only necessary when write.data = FALSE)
    data = RN4CAST_complete,
    monitor = c("intercept", "unit_precision", "hosp_precision", "deviance",
    "hosp_randomeffect"), # monitoro additionally all intercepts of random effect of hospitals
    burnin = burn_in_iterations, # make informed decision later (choosing speed here)
    sample = sample_iterations, # make informed decision later (choosing speed here)
    method = "rjags"
)
```

##### Visualization

Before assessing the model based through formal measures, we first do a
visual inspection. Various plot types are available:
`plot.type = c("trace", "ecdf", "histogram", "autocorr", "crosscorr")`.
You can also specify for which variable you want the plot. The different
options are
`vars = c("intercept", "unit_precision", "hosp_precision", "deviance", "resid.sum.sq")`.

First we create a convenience function for plotting runjags objects.

```{r}
# Convenience function for plotting
plot_jags <- function(type, var) {
    plot(JAGS.mod_uniform, plot.type = type, vars = var)
    dev.off()
}
```

For example, here are the trace plots for the precision of the random
intercept for unit (`unit_precision`) and for hospital (`hosp_precision`):

```{r, message=FALSE, out.width="50%", fig.align='center'}
plot_jags("trace", "unit_precision")
plot_jags("autocorr", "unit_precision")
plot_jags("trace", "hosp_precision")
plot_jags("autocorr", "hosp_precision")
```

The autocorrelation seems limited: for `unit_precision`, the
autocorrelation is almost zero at lag 15. For `hosp_precision`, this is
even better. The trace plot for `unit_precision` looks fairly well,
although there are still quite some outliers. For `hosp_precision`, the
trace plot does not look so well.

##### Assessment model

The model ran, and we can inspect its results.

```{r}
summary(JAGS.mod_uniform)
```

The Gelman-Rubin ANOVA diagnostic (i.e. estimated potential scale
reduction factor - PSRF) is close to 1 for both the unit_precision and
the hosp_precision, which is the aim. However, the MCMC error is still
fairly large in comparison with the SD (1.0 for unit_precision and 0.9
for hosp_precision). Additional measures (longer chain, accelerating
measure) are necessary.

We subsequently obtain the DIC (Deviance Information Criterion) to
assess the model performance.

```{r}
dic_uniform <- extract(JAGS.mod_uniform, what = "dic")
dic_uniform
```

The results are the following:

-   Mean deviance: 8896
-   penalty 103.8
-   Penalized deviance: 9000

#### Further expand model
Extend model with additional samples (i.c. 30 000).

```{r}
JAGS.mod_uniform <- extend.jags(
    # model to extend
    JAGS.mod_uniform,
    # burnin = burn_in_iterations, # No need to include additional burnin now (default = 0) since we expand instead of rerun model??
    sample = more_sample_iterations, # make informed decision later (choosing speed here)
)
```

##### Visualization

Perform visual inspection of trace plots for `unit_precision` and `hosp_precision` for extended model.
<!--- using reference of previous code block does not seem to work --->
```{r-extend, ref.label=c('traceplots')}
```

```{r, message=FALSE, out.width="50%", fig.align='center'}
plot_jags("trace", "unit_precision")
plot_jags("autocorr", "unit_precision")
plot_jags("trace", "hosp_precision")
plot_jags("autocorr", "hosp_precision")
```
The trace plot for `unit_precision` looks again fairly well,
although there are still quite some outliers. For `hosp_precision`, the
trace plot does not look so well. There still seem to be quite some outlying values.


##### Assessment model

Then we inspect the results again.
<!--- using reference of previous code block does not seem to work --->
```{r-extend, ref.label='summary-mod'}
```

```{r}
summary(JAGS.mod_uniform)
```
The Gelman-Rubin ANOVA diagnostic (i.e. estimated potential scale
reduction factor - PSRF) is very close to 1 for both the unit_precision and
the hosp_precision, which is the aim. The MCMC error is decreased substantially
in comparison with the SD (0.6 for `unit_precision` and 0.4
for Â´hosp_precision`). 

We subsequently obtain the DIC (Deviance Information Criterion) to
assess the model performance.
<!--- using references?? --->
```{r}
dic_uniform <- extract(JAGS.mod_uniform, what = "dic")
dic_uniform
```

<!--- add results ?? --->


#### Rank hospitals
Apply `fitted` function to the `runjags` object. This obtains estimates for the random effects, both for `unit_precision` and `hosp_precision`.
``` {r fitted}
fitted <- fitted(
    object = JAGS.mod_uniform,
    show.summary = TRUE
)
``` 
This results in the following output (20 min computing time):
"""
JAGS model summary statistics from 50000 samples (chains = 5; adapt+burnin = 46000):
                                                                                                              
                        Lower95 Median Upper95   Mean      SD Mode     MCerr MC%ofSD SSeff       AC.10    psrf
regression_fitted[1]     10.942 13.232  15.652 13.276  1.2037   --  0.010955     0.9 12073   0.0090693  1.0004
regression_fitted[2]     10.942 13.232  15.652 13.276  1.2037   --  0.010955     0.9 12073   0.0090693  1.0004
regression_fitted[3]     10.942 13.232  15.652 13.276  1.2037   --  0.010955     0.9 12073   0.0090693  1.0004
regression_fitted[4]     10.942 13.232  15.652 13.276  1.2037   --  0.010955     0.9 12073   0.0090693  1.0004
regression_fitted[5]     10.942 13.232  15.652 13.276  1.2037   --  0.010955     0.9 12073   0.0090693  1.0004
regression_fitted[6]     10.942 13.232  15.652 13.276  1.2037   --  0.010955     0.9 12073   0.0090693  1.0004
regression_fitted[7]     10.942 13.232  15.652 13.276  1.2037   --  0.010955     0.9 12073   0.0090693  1.0004
regression_fitted[8]     6.3145 7.8954  9.4956 7.9223 0.81592   -- 0.0091939     1.1  7876    0.042947  1.0006
regression_fitted[9]     6.3145 7.8954  9.4956 7.9223 0.81592   -- 0.0091939     1.1  7876    0.042947  1.0006
...
 [ reached getOption("max.print") -- omitted 1029 rows ]
"""

Hence, this seems to yield a combined result (so combining all intercepts to obtain a fit). The fits are the same for each nurse in the same hospital and in the same hospital unit (f.e. the first unit has 7 nurses, so 7 identical estimates). It is unclear how to obtain specific estimates for random intercept for each hospital.

However, extracting the samplers yields 159 nodes, i.e. intercept, hosp_randomeffect[1] up until hosp_randomeffect[30] and unit_randomeffect[1] up until unit_randomeffect[126], unit_precision and hosp_precision. So perhaps we can extract using these nodes

``` {r ranked_nodes}
ranked_samplers <- extract(JAGS.mod_uniform, what = "samplers")
ranked_samplers
```
