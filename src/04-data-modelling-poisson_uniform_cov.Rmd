### Model with covariates: uniform prior for precision

The model is written down in a file, called `JAGSmodel_unif_cov.txt`, in our
current directory. 

#### Pilot model

##### Creating model

We run the following chunk to get the syntax for a model
with the intercepts, all covariates a user-specified uniform prior for the
precision, and 5 chains. The amount of chains is based on the generally
accepted heuristic that 3-5 chains are needed for more complex models:
  
```{r, message=FALSE, warning=FALSE}
model_unif_cov <- template.jags(
  formula = pa ~ (1 | unit) + (1 | hosp) + expe + full + unitsur + we + tech + teach + beds,
  data = RN4CAST_complete,
  file = "JAGSmodel_unif_cov.txt",
  precision.prior = "dunif(0.001, 100)",
  family = "poisson",
  write.data = FALSE,
  n.chains = 5
)
```


We can now just run the model directly from `R` without needing to
manually copy/paste anything. For this, we use the `run.jags` function
to run the model we just specified our syntax for. We choose a limited
burn-in (4000) and sample (10000) to allow for an initial pilot run.
<!--- Should method=rjags be  used in original model design (see documentation extend.jags - then no need to recompile model when extending) ? --->
  
```{r cache=TRUE}
JAGS.mod_uniform_cov <- run.jags(
  # specify the syntax file
  model_unif_cov,
  # specify the data source (only necessary when write.data = FALSE)
  data = RN4CAST_complete,
  monitor = c(
    "intercept", "unit_precision", "hosp_precision",
    "expe_coefficient", "full_effect", "unitsur_effect",
    "we_coefficient", "tech_effect", "teach_effect", "beds_coefficient",
    "deviance", "dic"
  ),
  burnin = burn_in_iterations, # make informed decision later (choosing speed here)
  sample = sample_iterations, # make informed decision later (choosing speed here)
  method = "rjags"
)
```

##### Visualization

Before assessing the model based through formal measures, we first do a
visual inspection. Various plot types are available:
  `plot.type = c("trace", "ecdf", "histogram", "autocorr", "crosscorr")`.
You can also specify for which variable you want the plot. The different
options are
`vars = c("intercept", "unit_precision", "hosp_precision", "deviance", "resid.sum.sq")`.

First we create a convenience function for plotting runjags objects.

```{r}
# Convenience function for plotting
plot_jags <- function(type, var) {
  plot(JAGS.mod_uniform_cov, plot.type = type, vars = var)
}
```

For example, here are the trace plots for the precision of the random
intercept for unit (`unit_precision`) and for hospital (`hosp_precision`), 
as well as for the covariates:
  
```{r, message=FALSE, out.width="50%", fig.align='center'}
plot_jags("trace", "unit_precision")
plot_jags("trace", "hosp_precision")
plot_jags("trace", "expe_coefficient")
plot_jags("trace", "full_effect")
plot_jags("trace", "unitsur_effect")
plot_jags("trace", "we_coefficient")
plot_jags("trace", "tech_effect")
plot_jags("trace", "teach_effect")
plot_jags("trace", "beds_coefficient")

plot_jags("autocorr", "unit_precision")
plot_jags("autocorr", "hosp_precision")
plot_jags("autocorr", "expe_coefficient")
plot_jags("autocorr", "full_effect")
plot_jags("autocorr", "unitsur_effect")
plot_jags("autocorr", "we_coefficient")
plot_jags("autocorr", "tech_effect")
plot_jags("autocorr", "teach_effect")
plot_jags("autocorr", "beds_coefficient")
```

"""
The trace plot seem fairly ok. There are still quite some outliers, but none of the plots get stuck.

"""

##### Assessment model

The model ran, and we can inspect its results.

```{r-4}
summary(JAGS.mod_uniform_cov)
```

The Gelman-Rubin ANOVA diagnostic (i.e. estimated potential scale reduction factor - PSRF) is close to 1 for all parameters, which is the aim. However, the MCMC error is still fairly large in comparison with the SD, ranging from 0.5 to 1.2. Additional measures (longer chain, accelerating measure) are necessary.

We subsequently obtain the DIC (Deviance Information Criterion) to assess the model performance.

```{r}
dic_uniform_cov <- extract(JAGS.mod_uniform_cov, what = "dic")
dic_uniform_cov
```

The results are the following:
  
-   Mean deviance:  8895 
-   penalty 103.6 
-   Penalized deviance: 8999 


#### Further expand model
Extend model with additional samples (i.c. 30 000).

```{r}
JAGS.mod_uniform_cov <- extend.jags(
  # model to extend
  JAGS.mod_uniform_cov,
  # burnin = burn_in_iterations, # No need to include additional burnin now (default = 0) since we expand instead of rerun model??
  sample = more_sample_iterations, # make informed decision later (choosing speed here)
)
```

##### Visualization

Perform visual inspection of trace plots for extended model.
<!--- using reference of previous code block does not seem to work --->
```{r-extend, ref.label=c('traceplots')}
```

```{r, message=FALSE, out.width="50%", fig.align='center'}
plot_jags("trace", "unit_precision")
plot_jags("trace", "hosp_precision")
plot_jags("trace", "expe_coefficient")
plot_jags("trace", "full_effect")
plot_jags("trace", "unitsur_effect")
plot_jags("trace", "we_coefficient")
plot_jags("trace", "tech_effect")
plot_jags("trace", "teach_effect")
plot_jags("trace", "beds_coefficient")

plot_jags("autocorr", "unit_precision")
plot_jags("autocorr", "hosp_precision")
plot_jags("autocorr", "expe_coefficient")
plot_jags("autocorr", "full_effect")
plot_jags("autocorr", "unitsur_effect")
plot_jags("autocorr", "we_coefficient")
plot_jags("autocorr", "tech_effect")
plot_jags("autocorr", "teach_effect")
plot_jags("autocorr", "beds_coefficient")
```
The trace plots look fairly well, with some outliers. None of the trace plots get stuck.


##### Assessment model

Then we inspect the results again.
<!--- using reference of previous code block does not seem to work --->
```{r-extend, ref.label='summary-mod'}
```

```{r}
summary(JAGS.mod_uniform_cov)
```

"""
The Gelman-Rubin ANOVA diagnostic (i.e. estimated potential scale reduction factor - PSRF) is close to 1 for all parameters, which is the aim. However, the MCMC error is still fairly large in comparison with the SD, ranging from 0.3 to 0.6. 

We subsequently obtain the DIC (Deviance Information Criterion) to assess the model performance.
"""
<!--- using references?? --->
```{r}
dic_uniform_cov <- extract(JAGS.mod_uniform_cov, what = "dic")
dic_uniform_cov
```

<!--- add results ?? --->


```{r}
summary(JAGS.mod_uniform_cov)
```

