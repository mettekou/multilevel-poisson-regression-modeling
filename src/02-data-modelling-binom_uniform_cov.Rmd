## Negative binomial
### Model with covariates: uniform prior for precision

The model is written down in a file, called `JAGSmodel_binom_uniform_cov.txt`, in our
current directory. 

#### Pilot model

##### Creating model

We run the following chunk to get the syntax for a model
with the intercepts, all covariates, user-specified uniform prior prior for the
precision, and 5 chains. The amount of chains is based on the generally
accepted heuristic that 3-5 chains are needed for more complex models:
  
```{r template-uniform, message=FALSE, warning=FALSE}
model_binom_uniform_cov <- template.jags(
  formula = pa ~ (1 | unit) + (1 | hosp) + expe + full + unitsur + we + tech + teach + beds,
  data = RN4CAST_complete,
  file = "JAGSmodel_binom_uniform_cov.txt",
  precision.prior = "dunif(0.001, 100)",
  family = "negative binomial",
  write.data = FALSE,
  n.chains = 5 
)
```


We can now just run the model directly from `R` without needing to
manually copy/paste anything. For this, we use the `run.jags` function
to run the model we just specified our syntax for. We choose a limited
burn-in (4000) and sample (10000) to allow for an initial pilot run.
<!--- Should method=rjags be  used in original model design (see documentation extend.jags - then no need to recompile model when extending) ? --->
  
```{r run-mod}
JAGS.mod_binom_uniform_cov <- run.jags(
  # specify the syntax file
  model_binom_uniform_cov,
  # specify the data source (only necessary when write.data = FALSE)
  data = RN4CAST_complete,
  monitor = c( "k","intercept", "unit_precision", "hosp_precision", 
               "expe_coefficient", "full_effect", "unitsur_effect", 
               "we_coefficient", "tech_effect", "teach_effect", "beds_coefficient",
               "deviance"),
  burnin = 4000, # make informed decision later (choosing speed here)
  sample = 10000, # make informed decision later (choosing speed here)
  method = "rjags" 
)
```

##### Visualization

Before assessing the model based through formal measures, we first do a
visual inspection. 

First we create a convenience function for plotting runjags objects.

```{r plot-function}
# Convenience function for plotting
plot_jags <- function(type, var) {
  plot(JAGS.mod_binom_uniform_cov, plot.type = type, vars = var)
}
```

For example, here are the trace plots for the precision of the random
intercept for unit (`unit_precision`) and for hospital (`hosp_precision`), 
as well as for the covariates:
  
```{r traceplots, message=FALSE, out.width="50%", fig.align='center'}
plot_jags("trace", "unit_precision")
plot_jags("trace", "hosp_precision")
plot_jags("trace", "expe_coefficient")
plot_jags("trace", "full_effect")
plot_jags("trace", "unitsur_effect")
plot_jags("trace", "we_coefficient")
plot_jags("trace", "tech_effect")
plot_jags("trace", "teach_effect")
plot_jags("trace", "beds_coefficient")
```

The trace plot for `hosp_precision` shows that two chains do not converge and do not explore the entire distribution. The three other chains however converge well. The trace plots for `tech`, `teach` and `beds` seem to inhibit quite some dependency, i.e. they explore the entire distribution but slowly. The other plots converge well. None of the plots get stuck. 
  
  
##### Assessment model
  
The model ran, and we can inspect its results.

```{r summary-mod}
summary(JAGS.mod_binom_uniform_cov)
```

The Gelman-Rubin ANOVA diagnostic (i.e. estimated potential scale reduction factor - PSRF) is close to 1 for all parameters, which is the aim. Only for  `hosp_precision` it amounts to 1.92. Also, the MCMC error is still fairly large in comparison with the SD, ranging from 0.5 to 5.0. Additional measures (longer chain, accelerating measure) are necessary.


We subsequently obtain the DIC (Deviance Information Criterion) to assess the model performance.
  
```{r dic}
dic_binom_uniform_cov <- extract(JAGS.mod_binom_uniform_cov, what = "dic") 
dic_binom_uniform_cov
```

The results are the following:
  
- Mean deviance:  5545 
- penalty 889 
- Penalized deviance: 6434

  
#### Further expand model
Extend model with additional samples (i.c. 30 000).

```{r extend-mod}
JAGS.mod_binom_uniform_cov <- extend.jags(
  # model to extend
  JAGS.mod_binom_uniform_cov,
  # burnin = 4000, # No need to include additional burnin now (default = 0) since we expand instead of rerun model??
  sample = 30000, # make informed decision later (choosing speed here)
)
```

##### Visualization

Perform visual inspection of trace plots for extended model.
<!--- using reference of previous code block does not seem to work --->
```{r traceplots-extend, ref.label=c('traceplots')}
```

```{r plots, message=FALSE, out.width="50%", fig.align='center'}
plot_jags("trace", "unit_precision")
plot_jags("trace", "hosp_precision")
plot_jags("trace", "expe_coefficient")
plot_jags("trace", "full_effect")
plot_jags("trace", "unitsur_effect")
plot_jags("trace", "we_coefficient")
plot_jags("trace", "tech_effect")
plot_jags("trace", "teach_effect")
plot_jags("trace", "beds_coefficient")
```

The trace plots remain the same as before expanding the model, although the dependency in the trace plots for `tech`, `teach` and `beds` is reduced.
  
##### Assessment model
  
Then we inspect the results again.
<!--- using reference of previous code block does not seem to work --->
```{r summary-mod-extend, ref.label='summary-mod'}
```

```{r summary-mod}
summary(JAGS.mod_binom_uniform_cov)
```
The Gelman-Rubin ANOVA diagnostic is close to 1 for all parameters, which is the aim. Only for  `hosp_precision` it still amounts to 1.87. Also, the MCMC error remains fairly large in comparison with the SD, ranging from 0.3 to 2.5. Additional measures (longer chain, accelerating measure) are necessary.

We subsequently obtain the DIC (Deviance Information Criterion) to assess the model performance.

<!--- using references?? --->
```{r dic}
dic_binom_uniform_cov <- extract(JAGS.mod_binom_uniform_cov, what = "dic") 
dic_binom_uniform_cov
```

The results are the following
- Mean deviance:  5546 
- penalty 888.9 
- Penalized deviance: 6435

  
  
  
